{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/kaggle/input/qwertttt')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from typing import *\n",
    "\n",
    "from MEOW_Models.MT_models import MEOW_MTM\n",
    "from MEOW_Models.Kernel_model import BertWithoutEmbedding\n",
    "\n",
    "from MEOW_Utils.Data_utils import*\n",
    "from MEOW_Utils.Training_utils import*\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 16\n",
    "EPOCH_NUM = 10\n",
    "\n",
    "INPUT_FILE_PATH_SQuAD = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Dataset_infile\\SQuAD.csv'\n",
    "# INPUT_FILE_PATH_SQuAD = r'/kaggle/input/qwertttt/Data_file/SQuAD.csv'\n",
    "\n",
    "SQuAD_DATASIZE = 100\n",
    "\n",
    "TEST_SIZE = 0.3\n",
    "PRETRAINED_MODULE_NAME = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\Data_utils.py:197: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['TKstart'][i], df_train['TKend'][i] = count_the_TKbeg_and_TKend(df_train.iloc[i]['context'], df_train.iloc[i]['answer_start'], df_train.iloc[i]['text'], tokenizer)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>label</th>\n",
       "      <th>TKstart</th>\n",
       "      <th>TKend</th>\n",
       "      <th>SEP_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a35d653788daf001a5f86a1</td>\n",
       "      <td>What are short round bedrock knobs?</td>\n",
       "      <td>Some rock formations in the path of a glacier ...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5acd449507355d001abf3b57</td>\n",
       "      <td>MAPS is the former name of which satellite?</td>\n",
       "      <td>BeiDou-2 (formerly known as COMPASS) is not an...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5acf90a577cf76001a685295</td>\n",
       "      <td>Who helped the rest of the world use the word ...</td>\n",
       "      <td>Historical narratives of manga tend to focus e...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>571aa29f10f8ca140030520e</td>\n",
       "      <td>Along with the Punjab, what did Muhammad bin W...</td>\n",
       "      <td>In the year 712, Muhammad bin Qasim, an Umayya...</td>\n",
       "      <td>Sindh</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a2ef0e3a83784001a7d25ad</td>\n",
       "      <td>What has maintained a strong presence in all t...</td>\n",
       "      <td>Contemporary a cappella includes many vocal gr...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  \\\n",
       "0  5a35d653788daf001a5f86a1   \n",
       "1  5acd449507355d001abf3b57   \n",
       "2  5acf90a577cf76001a685295   \n",
       "3  571aa29f10f8ca140030520e   \n",
       "4  5a2ef0e3a83784001a7d25ad   \n",
       "\n",
       "                                            question  \\\n",
       "0                What are short round bedrock knobs?   \n",
       "1        MAPS is the former name of which satellite?   \n",
       "2  Who helped the rest of the world use the word ...   \n",
       "3  Along with the Punjab, what did Muhammad bin W...   \n",
       "4  What has maintained a strong presence in all t...   \n",
       "\n",
       "                                             context   text  answer_start  \\\n",
       "0  Some rock formations in the path of a glacier ...                   -1   \n",
       "1  BeiDou-2 (formerly known as COMPASS) is not an...                   -1   \n",
       "2  Historical narratives of manga tend to focus e...                   -1   \n",
       "3  In the year 712, Muhammad bin Qasim, an Umayya...  Sindh           132   \n",
       "4  Contemporary a cappella includes many vocal gr...                   -1   \n",
       "\n",
       "   label  TKstart  TKend  SEP_ind  \n",
       "0      0        0      0      131  \n",
       "1      0        0      0       94  \n",
       "2      0        0      0      303  \n",
       "3      1       32     32      158  \n",
       "4      0        0      0      145  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#處理好 dataframe\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODULE_NAME)\n",
    "df_SQuAD = get_dataframe(INPUT_FILE_PATH_SQuAD, 'SQuAD', tokenizer, SQuAD_DATASIZE)\n",
    "\n",
    "df_SQuAD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function str.lower()>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"sfdasf\"\n",
    "l.lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithoutEmbedding: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertWithoutEmbedding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertWithoutEmbedding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_kernel_model = BertWithoutEmbedding.from_pretrained(PRETRAINED_MODULE_NAME)\n",
    "SQuAD_databox = DataBox(\n",
    "               bert_kernel_model = bert_kernel_model,\n",
    "               df_Data = df_SQuAD,\n",
    "               test_size = TEST_SIZE,\n",
    "               tokenizer = tokenizer,\n",
    "               label_nums = 2,\n",
    "               batch_size = BATCH_SIZE,\n",
    "               dataset_name = 'SQuAD'\n",
    "               )\n",
    "\n",
    "for i in SQuAD_databox.test_dataloader:\n",
    "    0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per epoc round's num is 4\n"
     ]
    }
   ],
   "source": [
    "MEOW_model = MEOW_MTM(bert_kernel_model, \n",
    "                      SQuAD_embedding_layer=SQuAD_databox.embedding_layer, \n",
    "                      device = DEVICE)\n",
    "\n",
    "# H = {\n",
    "#     \"train_loss\": [],\n",
    "#     \"train_acc\": [],\n",
    "#     \"val_loss\":[],\n",
    "#     \"val_acc\": []\n",
    "#     }\n",
    "\n",
    "Training_a_epoc_data_num = len(SQuAD_databox.training_dataset)\n",
    "Training_round = int(Training_a_epoc_data_num / BATCH_SIZE)\n",
    "\n",
    "Test_a_epoc_data_num = len(SQuAD_databox.test_dataset)\n",
    "Test_round = int(Test_a_epoc_data_num / BATCH_SIZE)\n",
    "\n",
    "print(f'Per epoc round\\'s num is {Training_round}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 iter :\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 4.00 GiB total capacity; 3.37 GiB already allocated; 0 bytes free; 3.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\QA_train.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QA_train.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m SQuAD_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(SQuAD_databox\u001b[39m.\u001b[39mtraining_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QA_train.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(Training_round):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QA_train.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# SQuAD\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QA_train.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     loss \u001b[39m=\u001b[39m Training(MEOW_model, SQuAD_iter, DEVICE, dataset_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSQuAD\u001b[39;49m\u001b[39m'\u001b[39;49m, do_optimize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QA_train.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# print(\"the SQuAD loss is : \", loss.item())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QA_train.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     SQuAD_training_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\Training_utils.py:137\u001b[0m, in \u001b[0;36mTraining\u001b[1;34m(MEOW_model, iter, device, dataset_name, do_optimize)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTraining\u001b[39m(MEOW_model : MEOW_MTM, \n\u001b[0;32m    132\u001b[0m              \u001b[39miter\u001b[39m,\n\u001b[0;32m    133\u001b[0m              device, \n\u001b[0;32m    134\u001b[0m              dataset_name,\n\u001b[0;32m    135\u001b[0m              do_optimize \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    136\u001b[0m              ):\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m training_dict[dataset_name](MEOW_model, \u001b[39miter\u001b[39;49m, device, dataset_name, do_optimize)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\Training_utils.py:56\u001b[0m, in \u001b[0;36mQA_training\u001b[1;34m(MEOW_model, iter, device, dataset_name, do_optimize)\u001b[0m\n\u001b[0;32m     53\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     54\u001b[0m token \u001b[39m=\u001b[39m token\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 56\u001b[0m loss \u001b[39m=\u001b[39m MEOW_model\u001b[39m.\u001b[39;49mmt_forward(task_type\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mQA\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     57\u001b[0m                              dataset_name \u001b[39m=\u001b[39;49m dataset_name,\n\u001b[0;32m     58\u001b[0m                              input_ids \u001b[39m=\u001b[39;49m input_ids, \n\u001b[0;32m     59\u001b[0m                              mask \u001b[39m=\u001b[39;49m mask, \n\u001b[0;32m     60\u001b[0m                              token_type_ids \u001b[39m=\u001b[39;49m token,\n\u001b[0;32m     61\u001b[0m                              SEPind \u001b[39m=\u001b[39;49m SEPind, \n\u001b[0;32m     62\u001b[0m                              start_pos \u001b[39m=\u001b[39;49m Start_pos,\n\u001b[0;32m     63\u001b[0m                              end_pos \u001b[39m=\u001b[39;49m End_pos)\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m do_optimize:\n\u001b[0;32m     66\u001b[0m     MEOW_model\u001b[39m.\u001b[39mmt_optimize(loss\u001b[39m=\u001b[39mloss, dataset_name\u001b[39m=\u001b[39mdataset_name)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Models\\MT_models.py:72\u001b[0m, in \u001b[0;36mMEOW_MTM.mt_forward\u001b[1;34m(self, task_type, dataset_name, input_ids, mask, token_type_ids, label, SEPind, start_pos, end_pos)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_dict[dataset_name](input_ids, mask, token_type_ids, label, SEPind)\n\u001b[0;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_dict[dataset_name](input_ids, mask, token_type_ids, SEPind, start_pos, end_pos)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Models\\MT_models.py:135\u001b[0m, in \u001b[0;36mMEOW_MTM.SQuAD_forward\u001b[1;34m(self, input_ids, mask, token_type_ids, SEPind, start_pos, end_pos)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSQuAD_forward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, mask, token_type_ids, SEPind, start_pos, end_pos):\n\u001b[1;32m--> 135\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSQuAD_model(input_ids, mask, token_type_ids, SEPind, start_pos, end_pos)\n\u001b[0;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Models\\ST_model.py:151\u001b[0m, in \u001b[0;36mBert_QA.forward\u001b[1;34m(self, input_ids, attention_mask, token, SEPind, start_pos, end_pos)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    141\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    142\u001b[0m     input_ids : torch\u001b[39m.\u001b[39mtensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m     end_pos : List\n\u001b[0;32m    148\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]: \u001b[39m# return loss only\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_layer(input_ids\u001b[39m=\u001b[39minput_ids, token_type_ids\u001b[39m=\u001b[39mtoken)\n\u001b[1;32m--> 151\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(embedding_output\u001b[39m=\u001b[39;49membedding_output, input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, token_type_ids \u001b[39m=\u001b[39;49m token)\n\u001b[0;32m    152\u001b[0m     last_hidden_layer \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state  \u001b[39m# (batch_size, sequence_length, hidden_size:768)\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Models\\Kernel_model.py:93\u001b[0m, in \u001b[0;36mBertWithoutEmbedding.forward\u001b[1;34m(self, embedding_output, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m     89\u001b[0m     encoder_extended_attention_mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m---> 93\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m     94\u001b[0m     embedding_output,\n\u001b[0;32m     95\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m     96\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m     97\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m     98\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m     99\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    100\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    101\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    102\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    103\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    104\u001b[0m )\n\u001b[0;32m    105\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    106\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:611\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    602\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    603\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    604\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    608\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    609\u001b[0m     )\n\u001b[0;32m    610\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 611\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    612\u001b[0m         hidden_states,\n\u001b[0;32m    613\u001b[0m         attention_mask,\n\u001b[0;32m    614\u001b[0m         layer_head_mask,\n\u001b[0;32m    615\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    616\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    617\u001b[0m         past_key_value,\n\u001b[0;32m    618\u001b[0m         output_attentions,\n\u001b[0;32m    619\u001b[0m     )\n\u001b[0;32m    621\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    622\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    498\u001b[0m         hidden_states,\n\u001b[0;32m    499\u001b[0m         attention_mask,\n\u001b[0;32m    500\u001b[0m         head_mask,\n\u001b[0;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    428\u001b[0m         hidden_states,\n\u001b[0;32m    429\u001b[0m         attention_mask,\n\u001b[0;32m    430\u001b[0m         head_mask,\n\u001b[0;32m    431\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    432\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    433\u001b[0m         past_key_value,\n\u001b[0;32m    434\u001b[0m         output_attentions,\n\u001b[0;32m    435\u001b[0m     )\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:331\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    328\u001b[0m     past_key_value \u001b[39m=\u001b[39m (key_layer, value_layer)\n\u001b[0;32m    330\u001b[0m \u001b[39m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m attention_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(query_layer, key_layer\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m))\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key_query\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    334\u001b[0m     seq_length \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 4.00 GiB total capacity; 3.37 GiB already allocated; 0 bytes free; 3.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    print(\"the {:d} iter :\".format(epoch+1))\n",
    "\n",
    "    #### training now\n",
    "    MEOW_model.train()\n",
    "\n",
    "    SQuAD_training_loss = 0.0\n",
    "    SQuAD_iter = iter(SQuAD_databox.training_dataloader)\n",
    "\n",
    "    for i in range(Training_round):\n",
    "        # SQuAD\n",
    "        loss = Training(MEOW_model, SQuAD_iter, DEVICE, dataset_name='SQuAD')\n",
    "        # print(\"the SQuAD loss is : \", loss.item())\n",
    "        SQuAD_training_loss += loss.item()\n",
    "\n",
    "    \n",
    "    SQuAD_avg_loss = SQuAD_training_loss / Training_round\n",
    "    SQuAD_databox.H['train_loss'].append(SQuAD_avg_loss)\n",
    "    SQuAD_f1_score = count_F1_score(MEOW_model, SQuAD_databox.df_train, tokenizer, DEVICE)\n",
    "\n",
    "    print(\"SQuAD train loss: {:.6f}\".format(SQuAD_avg_loss))\n",
    "    print('')\n",
    "\n",
    "\n",
    "    #### test now\n",
    "    MEOW_model.eval()\n",
    "    SQuAD_test_loss = 0.0\n",
    "    SQuAD_iter = iter(SQuAD_databox.test_dataloader)\n",
    "\n",
    "    for i in range(Test_round):\n",
    "        # SQuAD\n",
    "        loss = Test(MEOW_model, SQuAD_iter, DEVICE, dataset_name='SQuAD')\n",
    "        # print(\"the SQuAD loss is : \", loss.item())\n",
    "        SQuAD_test_loss += loss.item()\n",
    "\n",
    "\n",
    "    SQuAD_avg_loss = SQuAD_test_loss / Test_round\n",
    "    SQuAD_databox.H['test_loss'].append(SQuAD_avg_loss)\n",
    "    SQuAD_f1_score = count_F1_score(MEOW_model, SQuAD_databox.df_test, tokenizer, DEVICE)\n",
    "    \n",
    "    print(\"SQuAD test loss: {:.6f}, SQuAD f1 score: {:.4f}\".format(SQuAD_avg_loss, SQuAD_f1_score))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQuAD_f1_score = count_F1_score(MEOW_model, SQuAD_databox.df_train, tokenizer, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
