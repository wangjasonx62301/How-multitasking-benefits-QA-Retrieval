{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:12:42.707362Z","iopub.status.busy":"2023-03-12T06:12:42.706399Z","iopub.status.idle":"2023-03-12T06:12:42.719853Z","shell.execute_reply":"2023-03-12T06:12:42.718694Z","shell.execute_reply.started":"2023-03-12T06:12:42.707316Z"},"id":"DfPP69sn93Ee","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","\n","from transformers import BertTokenizer\n","from typing import *\n","\n","from MEOW_Models.ST_model import*\n","from MEOW_Models.MT_models import MEOW_MTM\n","from MEOW_Models.Kernel_model import BertWithoutEmbedding\n","from MEOW_Utils import Data_utils, MT_utils\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","BATCH_SIZE = 4\n","EPOCH_NUM = 10\n","\n","INPUT_FILE_PATH_SQuAD = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Data_file\\SQuAD.csv'\n","INPUT_FILE_PATH_CoLA = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Data_file\\CoLA_train.csv'\n","INPUT_FILE_PATH_MNLI = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Data_file\\MNLI_train.csv'\n","INPUT_FILE_PATH_RTE = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Data_file\\RTE_train.csv'\n","INPUT_FILE_PATH_Sentiment = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Data_file\\Sentiment_train.csv'\n","\n","SQuAD_DATASIZE = 500\n","CoLA_DATASIZE = 200\n","Sentiment_DATASIZE = 350\n","MNLI_DATASIZE = 300\n","RTE_DATASIZE = 200\n","\n","CoLA_num_labels = 2\n","Sentiment_num_labels = 5\n","MNLI_num_labels = 3\n","RTE_num_labels = 2\n","\n","# SQuAD_DATASIZE max value is 5000\n","# CoLA_DATASIZE max value is 5056\n","# Sentiment_DATASIZE max value is 27405\n","# MNLI_DATASIZE max value is 13191\n","# RTE_DATASIZE max value is 2482\n","\n","PRETRAINED_MODULE_NAME = 'bert-base-uncased'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-03-12T06:12:44.989700Z","iopub.status.busy":"2023-03-12T06:12:44.989285Z","iopub.status.idle":"2023-03-12T06:12:55.952908Z","shell.execute_reply":"2023-03-12T06:12:55.951673Z","shell.execute_reply.started":"2023-03-12T06:12:44.989651Z"},"id":"8I7oqT9NBAsd","outputId":"89fbeea8-175a-4cde-8ab2-5f8df087f195","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\Data_utils.py:158: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_train['TKstart'][i], df_train['TKend'][i] = count_the_TKbeg_and_TKend(df_train.iloc[i]['context'], df_train.iloc[i]['answer_start'], df_train.iloc[i]['text'], tokenizer)\n"]}],"source":["#處理好 dataframe\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODULE_NAME)\n","\n","df_train_CoLA = Data_utils.get_CoLA_df(INPUT_FILE_PATH_CoLA, CoLA_DATASIZE)\n","\n","df_train_Sentiment = Data_utils.get_Sentiment_df(INPUT_FILE_PATH_Sentiment, Sentiment_DATASIZE)\n","\n","df_train_MNLI = Data_utils.get_MNLI_df(INPUT_FILE_PATH_MNLI, tokenizer, MNLI_DATASIZE)\n","\n","df_train_RTE = Data_utils.get_RTE_df(INPUT_FILE_PATH_RTE, tokenizer, RTE_DATASIZE)\n","\n","df_train_SQuAD = Data_utils.get_SQuAD_df(INPUT_FILE_PATH_SQuAD, tokenizer, SQuAD_DATASIZE)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["CoLA_dataset = Data_utils.get_CoLA_dataset(df_train_CoLA, tokenizer, CoLA_num_labels)\n","\n","Sentiment_dataset = Data_utils.get_Sentiment_dataset(df_train_Sentiment, tokenizer, Sentiment_num_labels)\n","\n","MNLI_dataset = Data_utils.get_MNLI_dataset(df_train_MNLI, tokenizer, MNLI_num_labels)\n","\n","RTE_dataset = Data_utils.get_RTE_dataset(df_train_RTE, tokenizer, RTE_num_labels)\n","\n","SQuAD_dataset = Data_utils.get_SQuAD_dataset(df_train_SQuAD, tokenizer)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["CoLA_dataloader = Data_utils.get_CoLA_dataloader(CoLA_dataset, batch_size=BATCH_SIZE)\n","\n","Sentiment_dataloader = Data_utils.get_Sentiment_dataloader(Sentiment_dataset, batch_size=BATCH_SIZE)\n","\n","MNLI_dataloader = Data_utils.get_MNLI_dataloader(MNLI_dataset, batch_size=BATCH_SIZE)\n","\n","RTE_dataloader = Data_utils.get_RTE_dataloader(RTE_dataset, batch_size=BATCH_SIZE)\n","\n","SQuAD_dataloader = Data_utils.get_SQuAD_dataloader(SQuAD_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# check if the dataloader can run correctly \n","for i in CoLA_dataloader:\n","    0\n","for i in Sentiment_dataloader:\n","    0\n","for i in MNLI_dataloader:\n","    0\n","for i in RTE_dataloader:\n","    0\n","for i in SQuAD_dataloader:\n","    0"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-03-12T07:35:19.879696Z","iopub.status.busy":"2023-03-12T07:35:19.878778Z","iopub.status.idle":"2023-03-12T07:35:21.394274Z","shell.execute_reply":"2023-03-12T07:35:21.393139Z","shell.execute_reply.started":"2023-03-12T07:35:19.879646Z"},"id":"PvUgPNFEBcia","outputId":"ba23185a-d01f-42cf-deea-d13e299f27c6","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithoutEmbedding: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertWithoutEmbedding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertWithoutEmbedding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["#給每個任務embedding層\n","\n","bert_kernel_model = BertWithoutEmbedding.from_pretrained(PRETRAINED_MODULE_NAME)\n","GETEMBEDDING_helper =  MT_utils.get_bert_element(bertmodel=bert_kernel_model)\n","\n","CoLA_embedding_layer = GETEMBEDDING_helper.get_copy_embeddings_layer()\n","\n","Sentiment_embedding_layer = GETEMBEDDING_helper.get_copy_embeddings_layer()\n","\n","MNLI_embedding_layer = GETEMBEDDING_helper.get_copy_embeddings_layer()\n","\n","RTE_embedding_layer = GETEMBEDDING_helper.get_copy_embeddings_layer()\n","\n","SQuAD_embedding_layer = GETEMBEDDING_helper.get_copy_embeddings_layer()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["MEOW_model = MEOW_MTM(bert_kernel_model, \n","                    CoLA_embedding_layer, CoLA_num_labels,\n","                    Sentiment_embedding_layer, Sentiment_num_labels, \n","                    MNLI_embedding_layer, MNLI_num_labels, \n","                    RTE_embedding_layer, RTE_num_labels,\n","                    SQuAD_embedding_layer,\n","                    DEVICE)\n","\n","H_CoLA = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\":[],\n","    \"val_acc\": []\n","    }\n","\n","H_Sentiment = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\":[],\n","    \"val_acc\": []\n","    }\n","\n","H_MNLI = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\":[],\n","    \"val_acc\": []\n","    }\n","\n","H_RTE = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\":[],\n","    \"val_acc\": []\n","    }\n","\n","H_SQuAD = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\":[],\n","    \"val_acc\": []\n","    }"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'CoLA_dataloader' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MWOE_MT.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/MWOE_MT.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mround\u001b[39m \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m([\u001b[39mlen\u001b[39m(CoLA_dataloader), \u001b[39mlen\u001b[39m(Sentiment_dataloader), \u001b[39mlen\u001b[39m(MNLI_dataloader), \u001b[39mlen\u001b[39m(RTE_dataloader), \u001b[39mlen\u001b[39m(SQuAD_dataloader)])\n","\u001b[1;31mNameError\u001b[0m: name 'CoLA_dataloader' is not defined"]}],"source":["a_epoc_data_num = min([len(CoLA_dataset), len(Sentiment_dataset), len(MNLI_dataset), len(RTE_dataset), len(SQuAD_dataset)])\n","round = min([len(CoLA_dataloader), len(Sentiment_dataloader), len(MNLI_dataloader), len(RTE_dataloader), len(SQuAD_dataloader)])\n","print(f'Per epoc round\\'s num is {round}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 訓練\n","\n","for epoch in range(EPOCH_NUM):\n","    print(\"the {:d} iter :\".format(epoch+1))\n","\n","    MEOW_model.train()\n","\n","    CoLA_training_loss = 0.0\n","    Sentiment_training_loss = 0.0\n","    MNLI_training_loss = 0.0\n","    RTE_training_loss = 0.0\n","    SQuAD_training_loss = 0.0\n","    MT_training_loss = 0.0\n","\n","    CoLA_correct_num = 0.0\n","    Sentiment_correct_num = 0.0\n","    MNLI_correct_num = 0.0\n","    RTE_correct_num = 0.0\n","\n","    CoLA_iter = iter(CoLA_dataloader)\n","    Sentiment_iter = iter(Sentiment_dataloader)\n","    MNLI_iter = iter(MNLI_dataloader)\n","    RTE_iter = iter(RTE_dataloader)\n","    SQuAD_iter = iter(SQuAD_dataloader)\n","\n","    # training_correct = 0.0\n","\n","    for i in range(round):\n","        \n","        # CoLA first\n","        input_ids, mask, token, label = next(CoLA_iter)\n","\n","        input_ids = input_ids.to(DEVICE)\n","        mask = mask.to(DEVICE)\n","        token = token.to(DEVICE)\n","        label = label.to(DEVICE)\n","        \n","        loss, prob = MEOW_model.CoLA_forward(input_ids, mask, token, label)\n","        #print(\"the CoLA loss is : \", loss.item())\n","        MEOW_model.optimize_CoLA(loss)\n","        \n","        CoLA_training_loss += loss.item()\n","        MT_training_loss += loss.item()\n","        predict = torch.argmax(prob, dim=1)\n","        label = torch.argmax(label, dim=1)\n","        CoLA_correct_num += (predict == label).type(torch.int).sum()\n","\n","        # Sentiment\n","        input_ids, mask, token, label = next(Sentiment_iter)\n","\n","        input_ids = input_ids.to(DEVICE)\n","        mask = mask.to(DEVICE)\n","        token = token.to(DEVICE)\n","        label = label.to(DEVICE)\n","        \n","        loss, prob = MEOW_model.Sentiment_forward(input_ids, mask, token, label)\n","        #print(\"the Sentiment loss is : \", loss.item())\n","        MEOW_model.optimize_Sentiment(loss)\n","        \n","        Sentiment_training_loss += loss.item()\n","        MT_training_loss += loss.item()\n","        predict = torch.argmax(prob, dim=1)\n","        label = torch.argmax(label, dim=1)\n","        Sentiment_correct_num += (predict == label).type(torch.int).sum()\n","\n","        # MNLI\n","        input_ids, mask, token, label, SEPind  = next(MNLI_iter)\n","\n","        input_ids = input_ids.to(DEVICE)\n","        mask = mask.to(DEVICE)\n","        token = token.to(DEVICE)\n","        label = label.to(DEVICE)\n","        \n","        loss, prob = MEOW_model.MNLI_forward(input_ids, mask, token, label, SEPind)\n","        #print(\"the MNLI loss is : \", loss.item())\n","        MEOW_model.optimize_MNLI(loss)\n","        \n","        MNLI_training_loss += loss.item()\n","        MT_training_loss += loss.item()\n","        predict = torch.argmax(prob, dim=1)\n","        label = torch.argmax(label, dim=1)\n","        MNLI_correct_num += (predict == label).type(torch.int).sum()\n","\n","        # RTE\n","        input_ids, mask, token, label, SEPind  = next(RTE_iter)\n","\n","        input_ids = input_ids.to(DEVICE)\n","        mask = mask.to(DEVICE)\n","        token = token.to(DEVICE)\n","        label = label.to(DEVICE)\n","        \n","        loss, prob = MEOW_model.RTE_forward(input_ids, mask, token, label, SEPind)\n","        #print(\"the RTE loss is : \", loss.item())\n","        MEOW_model.optimize_RTE(loss)\n","        \n","        RTE_training_loss += loss.item()\n","        MT_training_loss += loss.item()\n","        predict = torch.argmax(prob, dim=1)\n","        label = torch.argmax(label, dim=1)\n","        RTE_correct_num += (predict == label).type(torch.int).sum()\n","\n","        # SQuAD\n","        input_ids, mask, token, SEPind, Start_pos, End_pos = next(SQuAD_iter)\n","\n","        input_ids = input_ids.to(DEVICE)\n","        mask = mask.to(DEVICE)\n","        token = token.to(DEVICE)\n","        label = label.to(DEVICE)\n","        \n","        loss = MEOW_model.SQuAD_forward(input_ids, mask, token, SEPind, Start_pos, End_pos)\n","        # print(\"the SQuAD loss is : \", loss.item())\n","        MEOW_model.optimize_SQuAD(loss)\n","        \n","        SQuAD_training_loss += loss.item()\n","        MT_training_loss += loss.item()\n","\n","\n","    CoLA_avg_loss = CoLA_training_loss / round\n","    Sentiment_avg_loss = Sentiment_training_loss / round\n","    MNLI_avg_loss = MNLI_training_loss / round\n","    RTE_avg_loss = RTE_training_loss / round\n","    SQuAD_avg_loss = SQuAD_training_loss / round\n","    \n","    CoLA_accuracy = CoLA_correct_num / a_epoc_data_num\n","    Sentiment_accuracy = Sentiment_correct_num / a_epoc_data_num\n","    MNLI_accuracy = MNLI_correct_num / a_epoc_data_num\n","    RTE_accuracy = RTE_correct_num / a_epoc_data_num\n","    \n","    H_CoLA['train_loss'].append(CoLA_avg_loss)\n","    H_Sentiment['train_loss'].append(Sentiment_avg_loss)\n","    H_MNLI['train_loss'].append(MNLI_avg_loss)\n","    H_RTE['train_loss'].append(RTE_avg_loss)\n","    H_SQuAD['train_loss'].append(SQuAD_avg_loss)\n","    \n","    H_CoLA['train_acc'].append(CoLA_accuracy)\n","    H_Sentiment['train_acc'].append(Sentiment_accuracy)\n","    H_MNLI['train_acc'].append(MNLI_accuracy)\n","    H_RTE['train_acc'].append(RTE_accuracy)\n","\n","    # H['train_acc'].append(avg_correct)\n","    print(\"CoLA train loss: {:.6f}, CoLA accuracy: {:.4f}\".format(CoLA_avg_loss, CoLA_accuracy))\n","    print(\"Sentiment train loss: {:.6f}, Sentiment accuracy: {:.4f}\".format(Sentiment_avg_loss, Sentiment_accuracy))\n","    print(\"MNLI train loss: {:.6f}, MNLI accuracy: {:.4f}\".format(MNLI_avg_loss, MNLI_accuracy))\n","    print(\"RTE train loss: {:.6f}, RTE accuracy: {:.4f}\".format(RTE_avg_loss, RTE_accuracy))\n","    print(\"SQuAD train loss: {:.6f}\".format(SQuAD_avg_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MT_utils.plot_diagram(H=H_CoLA, epoch_num=EPOCH_NUM, has_accuracy=True)"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
